{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u4DulNLMGqMXUsqgl3lU5uoE7AshUGh_",
      "authorship_tag": "ABX9TyOXTCZ6rT+Pi1QJm/JkjBOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arham5siddiqui/Mitigating-Linkability-Attacks-through-Differential-Privacy-enabled-Neural-Network-Training/blob/main/Step4_DP_Classification_Evaluation_Results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "5xWkWB-nYDIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and implementing DP, table formation from the results"
      ],
      "metadata": {
        "id": "lJ51Rnoh5c0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for adding noise, and generating matplotlib graphs was referred online. Changes were made according to the metrics required for evaluation.\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    'SVC': SVC(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Placeholder lists for results\n",
        "results = []\n",
        "\n",
        "train_path = '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Reduced_Combined_Train.csv'\n",
        "test_path = '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Reduced_Combined_Test.csv'\n",
        "\n",
        "chunk_size = 10000  # size for chunks due to large dataset and limited RAM\n",
        "\n",
        "# Adding Laplace noise for differential privacy\n",
        "def add_laplace_noise(data, epsilon=1.0, sensitivity=1.0):\n",
        "    noise = np.random.laplace(loc=0, scale=sensitivity/epsilon, size=data.shape)\n",
        "    return data + noise\n",
        "\n",
        "# Adding Gaussian noise for differential privacy\n",
        "def add_gaussian_noise(data, epsilon=1.0, delta=1e-5, sensitivity=1.0):\n",
        "    sigma = np.sqrt(2 * np.log(1.25 / delta)) * (sensitivity / epsilon)\n",
        "    noise = np.random.normal(loc=0, scale=sigma, size=data.shape)\n",
        "    return data + noise\n",
        "\n",
        "# Adding noise to the test data (here we're using Laplace noise)\n",
        "epsilon = 1.0  # Privacy parameter\n",
        "sensitivity = 1.0  # Sensitivity of the data\n",
        "X_test_noisy = add_laplace_noise(X_test, epsilon, sensitivity)\n",
        "\n",
        "# Epsilon values for differential privacy for each classifier\n",
        "epsilons = {\n",
        "    'SVC': 0.5,\n",
        "    'Naive Bayes': 0.8,\n",
        "    'Decision Tree': 0.7,\n",
        "    'Random Forest': 0.6,\n",
        "    'KNN': 0.9\n",
        "}\n",
        "\n",
        "# Loop to read training data in chunks and train classifiers\n",
        "for chunk in pd.read_csv(train_path, chunksize=chunk_size):\n",
        "    X_train = chunk.drop(['userID', 'videoID'], axis=1)  # drop labels\n",
        "    y_train_user = chunk['userID']\n",
        "\n",
        "    # Training classifiers on user identification\n",
        "    for name, clf in classifiers.items():\n",
        "        epsilon = epsilons[name]  # Fetch epsilon value for the classifier\n",
        "        X_train_noisy = add_laplace_noise(X_train, epsilon, sensitivity)  # Apply differential privacy with the fetched epsilon\n",
        "\n",
        "        start_time = time.time()\n",
        "        clf.fit(X_train_noisy, y_train_user)\n",
        "        fit_time = time.time() - start_time  # in seconds\n",
        "        results.append({'Classifier': name, 'Fit_time': fit_time, 'Epsilon': epsilon})\n",
        "\n",
        "# Loop to read test data in chunks and evaluate classifiers\n",
        "for chunk in pd.read_csv(test_path, chunksize=chunk_size):\n",
        "    X_test = chunk.drop(['userID', 'videoID'], axis=1)  # drop labels\n",
        "    y_test_user = chunk['userID']\n",
        "\n",
        "    # Evaluate classifiers on user identification\n",
        "    for name, clf in classifiers.items():\n",
        "        epsilon = epsilons[name]  # Fetch epsilon value for the classifier\n",
        "        X_test_noisy = add_laplace_noise(X_test, epsilon, sensitivity)  # Apply differential privacy with the fetched epsilon\n",
        "\n",
        "        y_pred = clf.predict(X_test_noisy)\n",
        "        test_accuracy = accuracy_score(y_test_user, y_pred)\n",
        "        train_accuracy = clf.score(X_train_noisy, y_train_user)  # Using the last chunk for demonstration\n",
        "        results.append({'Classifier': name, 'Test Accuracy': test_accuracy, 'Train Accuracy': train_accuracy, 'Epsilon': epsilon})\n",
        "\n",
        "# Convert results to DataFrame and save as CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/main_table.csv', index=False)\n",
        "\n",
        "# Generate separate tables for each classifier and save them\n",
        "for classifier in classifiers.keys():\n",
        "    classifier_df = results_df[results_df['Classifier'] == classifier]\n",
        "    classifier_df.to_csv(f'/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/{classifier}_updated_table.csv', index=False)\n"
      ],
      "metadata": {
        "id": "LpqlmT_pUjCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphs from the Tables obtained"
      ],
      "metadata": {
        "id": "cGY8u76y5nzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plotting individual classifier graphs based on the tables obtained\n",
        "def plot_classifier_graph_from_table(title, table_path):\n",
        "    df = pd.read_csv(table_path)\n",
        "\n",
        "    # Extract relevant data\n",
        "    datasets = df['Datasets'].tolist()\n",
        "    test_accuracies_before_dp = df['Test Accuracy (Before DP)'].tolist()\n",
        "    test_accuracies_after_dp = df['Test Accuracy (After DP)'].tolist()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Plot bars for Test Accuracy (before DP)\n",
        "    plt.bar(datasets, test_accuracies_before_dp, color='#1f77b4', label='Before DP')\n",
        "\n",
        "    # Plot bars for Test Accuracy (after DP)\n",
        "    plt.bar(datasets, test_accuracies_after_dp, color='#ff7f0e', label='After DP', alpha=0.6)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Datasets')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.title(f'{title} Classifier: After Differential Privacy')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    # Save the plot as a PNG file\n",
        "    save_path = f'/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/{title}.png'  # As, running code in Google Colab\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to plot the Main Graph based on the table\n",
        "def plot_main_graph_from_table(table_path):\n",
        "    df = pd.read_csv(table_path)\n",
        "\n",
        "    # Extract relevant data\n",
        "    classifiers = df['Classifier'].tolist()\n",
        "    avg_test_accuracy_before_dp = df['Average Test Accuracy (Before DP)'].tolist()\n",
        "    avg_test_accuracy_after_dp = df['Average Test Accuracy (After DP)'].tolist()\n",
        "\n",
        "    # Create the plot\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    # Plot bars for Average Test Accuracy\n",
        "    plt.barh(classifiers, avg_test_accuracy_before_dp, color='#1f77b4', label='Before DP')\n",
        "    plt.barh(classifiers, avg_test_accuracy_after_dp, color='#ff7f0e', label='After DP', alpha=0.6)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Average Test Accuracy')\n",
        "    plt.ylabel('Classifiers')\n",
        "    plt.title('Average Test Accuracy Before and After Implementing Differential Privacy')\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    # Save the plot as a PNG file\n",
        "    save_path = '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/MainGraph.png'  # As, ran in Google Colab\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Paths to the reference tables uploaded in Google Colab\n",
        "table_paths = {\n",
        "    'Main Graph': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/main_table.csv',\n",
        "    'Naive Bayes': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/Naive_Bayes_updated_table.csv',\n",
        "    'Decision Tree': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/Decision_Tree_updated_table.csv',\n",
        "    'Random Forest': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/Random_Forest_updated_table.csv',\n",
        "    'SVM': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/SVC_updated_table.csv',\n",
        "    'KNN': '/content/drive/MyDrive/MSc Project/Formated_Data/Experiment_1/TrainTestDataset/Results/KNN_updated_table.csv'\n",
        "}\n",
        "\n",
        "# Plot the Main Graph\n",
        "plot_main_graph_from_table(table_paths['Main Graph'])\n",
        "\n",
        "# Plot graphs for individual classifiers\n",
        "for title, table_path in {k: v for k, v in table_paths.items() if k != 'Main Graph'}.items():\n",
        "    plot_classifier_graph_from_table(title, table_path)\n"
      ],
      "metadata": {
        "id": "KsFesBdK1puX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step5(Optional): Added Metric for Evaluation. (F1-Score)\n",
        "Other than Accuracy and Epsilon values"
      ],
      "metadata": {
        "id": "wqQvV94H6LWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, clf in classifiers.items():\n",
        "    # Train the model\n",
        "    clf.fit(X_train, y_train_user)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test_user, y_pred)\n",
        "    f1 = f1_score(y_test_user, y_pred, average='weighted')  # 'weighted' can be changed based on specific use-case\n",
        "\n",
        "    print(f\"{name} Classifier F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "P7F3YTpJ6KwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}